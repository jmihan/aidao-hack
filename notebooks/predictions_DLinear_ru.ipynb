{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3a30e5",
   "metadata": {},
   "source": [
    "# Бейзлайн решение\n",
    "\n",
    "В рамках олимпиады вам предстоит решить задачу по адаптация скорости LDPC-кодов для постобработки в квантовой криптографии.\n",
    "\n",
    "В данном Jupyter ноутбуке представлено бейзлайн решение, которое позволяет получить файл предсказания в нужном для проверяющей системы формате. Он тестировался с библиотеками из ```requirements.txt``` и версией ```Python 3.12.11```.\n",
    "\n",
    "#### Желаем удачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600387d6",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae68e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11beae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков: 579\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"frames_errors.csv\", header=None)\n",
    "df.columns = [\n",
    "    \"block_id\",\n",
    "    \"frame_idx\",\n",
    "    \"E_mu_Z\",\n",
    "    \"E_mu_phys_est\",\n",
    "    \"E_mu_X\",\n",
    "    \"E_nu1_X\",\n",
    "    \"E_nu2_X\",\n",
    "    \"E_nu1_Z\",\n",
    "    \"E_nu2_Z\",\n",
    "    \"N_mu_X\",\n",
    "    \"M_mu_XX\",\n",
    "    \"M_mu_XZ\",\n",
    "    \"M_mu_X\",\n",
    "    \"N_mu_Z\",\n",
    "    \"M_mu_ZZ\",\n",
    "    \"M_mu_Z\",\n",
    "    \"N_nu1_X\",\n",
    "    \"M_nu1_XX\",\n",
    "    \"M_nu1_XZ\",\n",
    "    \"M_nu1_X\",\n",
    "    \"N_nu1_Z\",\n",
    "    \"M_nu1_ZZ\",\n",
    "    \"M_nu1_Z\",\n",
    "    \"N_nu2_X\",\n",
    "    \"M_nu2_XX\",\n",
    "    \"M_nu2_XZ\",\n",
    "    \"M_nu2_X\",\n",
    "    \"N_nu2_Z\",\n",
    "    \"M_nu2_ZZ\",\n",
    "    \"M_nu2_Z\",\n",
    "    \"nTot\",\n",
    "    \"bayesImVoltage\",\n",
    "    \"opticalPower\",\n",
    "    \"polarizerVoltages[0]\",\n",
    "    \"polarizerVoltages[1]\",\n",
    "    \"polarizerVoltages[2]\",\n",
    "    \"polarizerVoltages[3]\",\n",
    "    \"temp_1\",\n",
    "    \"biasVoltage_1\",\n",
    "    \"temp_2\",\n",
    "    \"biasVoltage_2\",\n",
    "    \"synErr\",\n",
    "    \"N_EC_rounds\",\n",
    "    \"maintenance_flag\",\n",
    "    \"estimator_name\",\n",
    "    \"f_EC\",\n",
    "    \"E_mu_Z_est\",\n",
    "    \"R\",\n",
    "    \"s\",\n",
    "    \"p\",\n",
    "]\n",
    "\n",
    "df_base = df.drop(\n",
    "    [\n",
    "        \"E_mu_phys_est\",\n",
    "        \"f_EC\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "print(f\"Количество пропусков: {df.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebaf76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_base.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f701bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество фреймов/Количество рядов\n",
      "date\n",
      "399    569\n",
      "400    251\n",
      "398      2\n",
      "390      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(\n",
    "    columns={\n",
    "        \"block_id\": \"id\",\n",
    "        \"E_mu_Z\": \"value\",\n",
    "        \"frame_idx\": \"date\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Смотрим на длину временных рядов по количеству фреймов\n",
    "timestamp_counts = df.groupby(\"id\")[\"date\"].nunique()\n",
    "print(\"Количество фреймов/Количество рядов\")\n",
    "print(timestamp_counts.value_counts())\n",
    "\n",
    "df_for_ts = df[[\"id\", \"value\", \"date\"]].dropna(subset=[\"value\"], how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91ebc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество фреймов/Количество рядов\n",
      "date\n",
      "400    815\n",
      "399      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_for_ts = df_for_ts.set_index([\"id\", \"date\"]).unstack().ffill().stack().reset_index()\n",
    "timestamp_counts = df_for_ts.groupby(\"id\")[\"date\"].nunique()\n",
    "print(\"Количество фреймов/Количество рядов\")\n",
    "print(timestamp_counts.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d282ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оставшиеся сегменты: 815\n"
     ]
    }
   ],
   "source": [
    "df_for_ts = df_for_ts.groupby(\"id\").filter(lambda x: len(x) == 400)\n",
    "print(\"Оставшиеся сегменты:\", df_for_ts[\"id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b1187",
   "metadata": {},
   "source": [
    "# DLinear\n",
    "\n",
    "`DLinear` — это простая и быстрая модель, которая выделяет тренд на основе AveragePooling, а затем на компонентах тренда и остатков применяет nn.Linear и собирает всё обратно. Ознакомиться с моделью можно в статье https://arxiv.org/abs/2205.13504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49af1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "import sys\n",
    "\n",
    "c_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(c_handler)\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "from tsururu.dataset import Pipeline, TSDataset\n",
    "from tsururu.model_training.trainer import DLTrainer\n",
    "from tsururu.model_training.validator import HoldOutValidator\n",
    "from tsururu.strategies import RecursiveStrategy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd932e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg(Module):\n",
    "    \"\"\"Блок скользящего среднего для выделения тренда временного ряда.\n",
    "\n",
    "    Аргументы:\n",
    "        kernel_size: размер окна свёртки (ядра).\n",
    "        stride: шаг скользящего среднего.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: int, stride: int):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x: \"torch.Tensor\") -> \"torch.Tensor\":\n",
    "        \"\"\"Прямой проход для вычисления скользящего среднего.\n",
    "\n",
    "        Аргументы:\n",
    "            x: входной тензор.\n",
    "\n",
    "        Возвращает:\n",
    "            тензор после применения скользящего среднего.\n",
    "\n",
    "        \"\"\"\n",
    "        # добавляем паддинг (повторяем крайние значения) с обеих сторон временного ряда\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "\n",
    "        # применяем скользящее среднее по временной оси\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(Module):\n",
    "    \"\"\"Блок декомпозиции временного ряда.\n",
    "\n",
    "    Аргументы:\n",
    "        kernel_size: размер окна для скользящего среднего.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: int):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x: \"torch.Tensor\") -> tuple[\"torch.Tensor\", \"torch.Tensor\"]:\n",
    "        \"\"\"Прямой проход для декомпозиции ряда на тренд и остаток.\n",
    "\n",
    "        Аргументы:\n",
    "            x: входной тензор.\n",
    "\n",
    "        Возвращает:\n",
    "            кортеж тензоров (остаток, тренд).\n",
    "\n",
    "        \"\"\"\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "class DLinear_NN(Module):\n",
    "    def __init__(self, features_groups, pred_len, seq_len, moving_avg=25, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # Защита от типовых «обёрток»\n",
    "        def _to_int(x):\n",
    "            if isinstance(x, int):\n",
    "                return x\n",
    "            if isinstance(x, dict) and \"value\" in x:\n",
    "                return int(x[\"value\"])\n",
    "            try:\n",
    "                return int(x)\n",
    "            except Exception:\n",
    "                raise TypeError(f\"Expected int-like, got {type(x)}: {x}\")\n",
    "\n",
    "        # Если вдруг пришли ещё и именованные — заберём их, чтобы не мешали\n",
    "        seq_len = _to_int(kwargs.pop(\"seq_len\", seq_len))\n",
    "        pred_len = _to_int(kwargs.pop(\"pred_len\", pred_len))\n",
    "        moving_avg = int(kwargs.pop(\"moving_avg\", moving_avg))\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.decompsition = series_decomp(moving_avg)\n",
    "        self.Linear_Seasonal = nn.Linear(self.seq_len, self.pred_len)\n",
    "        self.Linear_Trend = nn.Linear(self.seq_len, self.pred_len)\n",
    "\n",
    "        self.Linear_Seasonal.weight = nn.Parameter(\n",
    "            (1 / self.seq_len) * torch.ones([self.pred_len, self.seq_len])\n",
    "        )\n",
    "        self.Linear_Trend.weight = nn.Parameter(\n",
    "            (1 / self.seq_len) * torch.ones([self.pred_len, self.seq_len])\n",
    "        )\n",
    "\n",
    "    def forward(self, x: \"torch.Tensor\") -> \"torch.Tensor\":\n",
    "        \"\"\"Прямой проход модели.\n",
    "\n",
    "        Аргументы:\n",
    "            x: входной тензор формы (batch_size, seq_len, num_features).\n",
    "\n",
    "        Возвращает:\n",
    "            выходной тензор формы (batch_size, pred_len, num_features).\n",
    "\n",
    "        \"\"\"\n",
    "        # Декомпозиция временного ряда на тренд и остаток (сезонность)\n",
    "        seasonal_init, trend_init = self.decompsition(x)\n",
    "\n",
    "        # Транспонируем тензоры в формат (batch_size, num_features, seq_len)\n",
    "        seasonal_init, trend_init = seasonal_init.permute(0, 2, 1), trend_init.permute(\n",
    "            0, 2, 1\n",
    "        )\n",
    "\n",
    "        # Применяем линейные слои к тренду и остаткам\n",
    "        seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "        trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        # Складываем результаты линейных слоёв\n",
    "        x = seasonal_output + trend_output\n",
    "\n",
    "        # Транспонируем обратно в формат (batch_size, seq_len, num_features)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x[:, -self.pred_len :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7403fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем предсказывать 8 чисел вперед с окном 160\n",
    "\n",
    "HORIZON = 8\n",
    "HISTORY = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f7bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма обучающего набора: (312960, 3)\n",
      "Форма валидационного набора: (136920, 3)\n",
      "Форма тестового набора: (130400, 3)\n",
      "Форма целевых значений теста: (6520, 3)\n",
      "Количество рядов в обучающем наборе: 815\n",
      "Количество рядов в валидационном наборе: 815\n",
      "Количество рядов в тестовом наборе: 815\n",
      "Количество рядов в целевых значениях теста: 815\n"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "val_df = []\n",
    "test_df = []\n",
    "test_targets = []\n",
    "for current_id in df_for_ts[\"id\"].unique():\n",
    "    current_df = df_for_ts[df_for_ts[\"id\"] == current_id]\n",
    "    train_df.append(current_df.iloc[: -2 * HORIZON])\n",
    "    val_df.append(current_df.iloc[-2 * HORIZON - HISTORY : -HORIZON])\n",
    "    test_df.append(current_df.iloc[-HORIZON - HISTORY : -HORIZON])\n",
    "    test_targets.append(current_df.iloc[-HORIZON:])\n",
    "train_df = pd.concat(train_df)\n",
    "val_df = pd.concat(val_df)\n",
    "test_df = pd.concat(test_df)\n",
    "test_targets = pd.concat(test_targets)\n",
    "\n",
    "\n",
    "print(f\"Форма обучающего набора: {train_df.shape}\")\n",
    "print(f\"Форма валидационного набора: {val_df.shape}\")\n",
    "print(f\"Форма тестового набора: {test_df.shape}\")\n",
    "print(f\"Форма целевых значений теста: {test_targets.shape}\")\n",
    "\n",
    "print(f\"Количество рядов в обучающем наборе: {train_df['id'].nunique()}\")\n",
    "print(f\"Количество рядов в валидационном наборе: {val_df['id'].nunique()}\")\n",
    "print(f\"Количество рядов в тестовом наборе: {test_df['id'].nunique()}\")\n",
    "print(f\"Количество рядов в целевых значениях теста: {test_targets['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa379e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем базовую дату (первый день)\n",
    "# Это необходимо для корректной работы библиотеки tsururu и не влияет на суть задачи\n",
    "\n",
    "base_date = pd.to_datetime(\"2000-01-01\")\n",
    "\n",
    "\n",
    "def convert_dates(series):\n",
    "    return base_date + pd.to_timedelta(series.astype(int) - 1, unit=\"D\")\n",
    "\n",
    "\n",
    "# Применяем ко всем DataFrame\n",
    "\n",
    "train_df[\"date\"] = convert_dates(train_df[\"date\"])\n",
    "val_df[\"date\"] = convert_dates(val_df[\"date\"])\n",
    "test_df[\"date\"] = convert_dates(test_df[\"date\"])\n",
    "test_targets[\"date\"] = convert_dates(test_targets[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e36220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a8d352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tsururu.dataset.dataset:freq: Day; period: 1\n"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "dataset_params = {\n",
    "    \"target\": {\n",
    "        \"columns\": [\"value\"],\n",
    "        \"type\": \"continuous\",\n",
    "    },\n",
    "    \"date\": {\n",
    "        \"columns\": [\"date\"],\n",
    "        \"type\": \"datetime\",\n",
    "    },\n",
    "    \"id\": {\n",
    "        \"columns\": [\"id\"],\n",
    "        \"type\": \"categorical\",\n",
    "    },\n",
    "}\n",
    "\n",
    "train_dataset = TSDataset(\n",
    "    data=train_df,\n",
    "    columns_params=dataset_params,\n",
    "    print_freq_period_info=True,\n",
    ")\n",
    "val_dataset = TSDataset(\n",
    "    data=val_df,\n",
    "    columns_params=dataset_params,\n",
    "    print_freq_period_info=False,\n",
    ")\n",
    "test_dataset = TSDataset(\n",
    "    data=test_df,\n",
    "    columns_params=dataset_params,\n",
    "    print_freq_period_info=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b90dfe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = {\n",
    "    \"target\": {\n",
    "        \"columns\": [\"value\"],\n",
    "        \"features\": {\n",
    "            \"DifferenceNormalizer\": {\n",
    "                \"regime\": \"delta\",\n",
    "                \"transform_target\": True,\n",
    "                \"transform_features\": True,\n",
    "            },\n",
    "            \"MissingValuesImputer\": {  # После DifferenceNormalizer у нас неизбежно появляются NaN в данных (в первом значении каждого сегмента)\n",
    "                \"constant_value\": 0,  # Заполним нулями\n",
    "                \"transform_target\": True,\n",
    "                \"transform_features\": True,\n",
    "            },\n",
    "            \"StandardScalerTransformer\": {  # И выровним значения рядов прежде чем подавать в DL модель\n",
    "                \"transform_target\": True,\n",
    "                \"transform_features\": True,\n",
    "                \"agg_by_id\": True,\n",
    "            },\n",
    "            \"LagTransformer\": {\"lags\": HISTORY},\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60966ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using GPU\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701d5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "DEVICE = choose_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "235ceb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настроим обучение\n",
    "\n",
    "pipeline = Pipeline.from_dict(pipeline_params, multivariate=False)\n",
    "\n",
    "validation = HoldOutValidator\n",
    "validation_params = {\"validation_data\": val_dataset}\n",
    "\n",
    "trainer_params = {\n",
    "    \"device\": DEVICE,\n",
    "    \"num_workers\": 4,\n",
    "    \"best_by_metric\": True,\n",
    "    \"save_to_dir\": False,\n",
    "    \"batch_size\": 128,\n",
    "    \"n_epochs\": 5,\n",
    "    \"early_stopping_patience\": 2,\n",
    "}\n",
    "\n",
    "\n",
    "trainer = DLTrainer(\n",
    "    model=DLinear_NN,\n",
    "    model_params={\"moving_avg\": 25},\n",
    "    validator=validation,\n",
    "    validation_params=validation_params,\n",
    "    **trainer_params,\n",
    ")\n",
    "\n",
    "\n",
    "strategy = RecursiveStrategy(\n",
    "    horizon=HORIZON,\n",
    "    model_horizon=4,\n",
    "    history=HISTORY,\n",
    "    pipeline=pipeline,\n",
    "    trainer=trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4030151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tsururu.model_training.trainer:length of train dataset: 180115\n",
      "INFO:tsururu.model_training.trainer:length of val dataset: 4075\n",
      "INFO:tsururu.model_training.trainer:Epoch 1/5, cost time: 32.73s\n",
      "INFO:tsururu.model_training.trainer:train loss: 0.7057\n",
      "INFO:tsururu.model_training.trainer:Validation, Loss: 0.6650, Metric: -0.6650\n",
      "INFO:tsururu.model_training.trainer:val loss: 0.6650, val metric: -0.6650\n",
      "INFO:tsururu.model_training.trainer:Epoch 2/5, cost time: 32.47s\n",
      "INFO:tsururu.model_training.trainer:train loss: 0.6827\n",
      "INFO:tsururu.model_training.trainer:Validation, Loss: 0.6613, Metric: -0.6613\n",
      "INFO:tsururu.model_training.trainer:val loss: 0.6613, val metric: -0.6613\n",
      "INFO:tsururu.model_training.trainer:Epoch 3/5, cost time: 32.85s\n",
      "INFO:tsururu.model_training.trainer:train loss: 0.6813\n",
      "INFO:tsururu.model_training.trainer:Validation, Loss: 0.6624, Metric: -0.6624\n",
      "INFO:tsururu.model_training.trainer:val loss: 0.6624, val metric: -0.6624\n",
      "INFO:tsururu.model_training.torch_based.callbacks:Early stopping counter: 1\n",
      "INFO:tsururu.model_training.trainer:Epoch 4/5, cost time: 32.71s\n",
      "INFO:tsururu.model_training.trainer:train loss: 0.6809\n",
      "INFO:tsururu.model_training.trainer:Validation, Loss: 0.6622, Metric: -0.6622\n",
      "INFO:tsururu.model_training.trainer:val loss: 0.6622, val metric: -0.6622\n",
      "INFO:tsururu.model_training.torch_based.callbacks:Early stopping counter: 2\n",
      "INFO:tsururu.model_training.torch_based.callbacks:Early stopping triggered\n",
      "INFO:tsururu.model_training.torch_based.callbacks:Training finished.\n",
      "INFO:tsururu.model_training.trainer:Fold 0. Score: -0.6621605753898621\n",
      "INFO:tsururu.model_training.trainer:Mean score: -0.6622\n",
      "INFO:tsururu.model_training.trainer:Std: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Запустим обучение\n",
    "\n",
    "fit_time, metrics = strategy.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6a003af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним модель для предоставления весов жюри\n",
    "\n",
    "import pickle\n",
    "\n",
    "model_filename = \"dlinear_strategy.pkl\"\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(strategy, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a94f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для предсказания загрузим уже обученную модель\n",
    "\n",
    "with open(model_filename, \"rb\") as f:\n",
    "    loaded_strategy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b704b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tsururu.dataset.dataset:freq: Day; period: 1\n",
      "INFO:tsururu.model_training.trainer:length of test dataset: 815\n",
      "INFO:tsururu.model_training.trainer:length of test dataset: 815\n"
     ]
    }
   ],
   "source": [
    "forecast_time, current_pred = loaded_strategy.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee464704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17612792</td>\n",
       "      <td>2001-01-26</td>\n",
       "      <td>0.018134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17612792</td>\n",
       "      <td>2001-01-27</td>\n",
       "      <td>0.017268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17612792</td>\n",
       "      <td>2001-01-28</td>\n",
       "      <td>0.018611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17612792</td>\n",
       "      <td>2001-01-29</td>\n",
       "      <td>0.020405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17612792</td>\n",
       "      <td>2001-01-30</td>\n",
       "      <td>0.019927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>2146878613</td>\n",
       "      <td>2001-01-29</td>\n",
       "      <td>0.023127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>2146878613</td>\n",
       "      <td>2001-01-30</td>\n",
       "      <td>0.02234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>2146878613</td>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>0.02058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>2146878613</td>\n",
       "      <td>2001-02-01</td>\n",
       "      <td>0.018715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>2146878613</td>\n",
       "      <td>2001-02-02</td>\n",
       "      <td>0.017496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       date     value\n",
       "0       17612792 2001-01-26  0.018134\n",
       "1       17612792 2001-01-27  0.017268\n",
       "2       17612792 2001-01-28  0.018611\n",
       "3       17612792 2001-01-29  0.020405\n",
       "4       17612792 2001-01-30  0.019927\n",
       "...          ...        ...       ...\n",
       "6515  2146878613 2001-01-29  0.023127\n",
       "6516  2146878613 2001-01-30   0.02234\n",
       "6517  2146878613 2001-01-31   0.02058\n",
       "6518  2146878613 2001-02-01  0.018715\n",
       "6519  2146878613 2001-02-02  0.017496\n",
       "\n",
       "[6520 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "690158eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_pred = current_pred.sort_values([\"id\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "ids = current_pred[\"id\"].unique().tolist()\n",
    "n_ids = len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59e53869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нам нужно вернуть 2000 точек значений\n",
    "TOTAL = 2000\n",
    "base = TOTAL // n_ids  # базовое число точек на id\n",
    "rem = TOTAL % n_ids  # первым rem id дадим на 1 точку больше\n",
    "\n",
    "if base == 0:\n",
    "    # Случай, если рядов слишком много (n_ids > 2000): берём по 1 точке для первых 2000 id\n",
    "    selected_ids = ids[:TOTAL]\n",
    "    compressed_values = []\n",
    "    for i in selected_ids:\n",
    "        arr = current_pred.loc[current_pred[\"id\"] == i, \"value\"].to_numpy()\n",
    "        # берём, например, последнее значение горизонта\n",
    "        compressed_values.append(float(arr[-1]))\n",
    "else:\n",
    "    # Обычный случай (~815 рядов): base=2, rem=2000-2*815=370 => 370 рядов дадут 3 точки, остальные 2\n",
    "    compressed_values = []\n",
    "    for idx, i in enumerate(ids):\n",
    "        k = base + (1 if idx < rem else 0)  # целевых точек для этого id\n",
    "        arr = current_pred.loc[current_pred[\"id\"] == i, \"value\"].to_numpy()\n",
    "\n",
    "        # Защита: если горизонт < k (не должно быть), просто повторим последние\n",
    "        if len(arr) < k:\n",
    "            arr = np.pad(arr, (0, k - len(arr)), mode=\"edge\")\n",
    "\n",
    "        # Режем на k ~равных кусков и усредняем каждый\n",
    "        chunks = np.array_split(arr, k)\n",
    "        means = [float(np.mean(c)) for c in chunks]\n",
    "        compressed_values.extend(means)\n",
    "\n",
    "# Получаем ровно 2000 значений в фиксированном порядке\n",
    "target_df = pd.DataFrame({\"value\": compressed_values})\n",
    "assert len(target_df) == 2000, f\"Got {len(target_df)} instead of 2000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41cfd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "alpha = 0.33\n",
    "f_ec = 1.15\n",
    "R_range = [\n",
    "    round(0.50 + 0.05 * x, 2) for x in range(9)\n",
    "]  # 0.50..0.90 для соответствия условию задачи\n",
    "n = 32000\n",
    "d = 4800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e88b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ema(prev_ema, current_value, alpha):\n",
    "    if prev_ema is None:\n",
    "        return current_value\n",
    "    return alpha * current_value + (1 - alpha) * prev_ema\n",
    "\n",
    "\n",
    "def h(x):\n",
    "    if x > 0:\n",
    "        return -x * np.log2(x) - (1 - x) * np.log2(1 - x)\n",
    "    elif x == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        raise ValueError(\"Invalid x for binary entropy\")\n",
    "\n",
    "\n",
    "def select_code_rate(e_mu, f_ec, rates, frame_len, sp_count):\n",
    "    r_candidate = 1 - h(e_mu) * f_ec\n",
    "    R_res = 0.50\n",
    "    s_n = sp_count\n",
    "    p_n = 0\n",
    "    for R in rates:\n",
    "        p_n = int(\n",
    "            ceil((1 - R) * frame_len - (1 - r_candidate) * (frame_len - sp_count))\n",
    "        )\n",
    "        s_n = int(sp_count - p_n)\n",
    "        if p_n >= 0 and s_n >= 0:\n",
    "            R_res = R\n",
    "            return round(R_res, 2), s_n, p_n\n",
    "    return round(R_res, 2), s_n, p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "555058a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_series = (\n",
    "    pd.to_numeric(target_df.iloc[:, 0], errors=\"coerce\").dropna().reset_index(drop=True)\n",
    ")\n",
    "\n",
    "prev_ema = None\n",
    "rows = []\n",
    "for E_mu_Z in E_series:\n",
    "    ema_value = calculate_ema(prev_ema, float(E_mu_Z), alpha)\n",
    "    prev_ema = ema_value\n",
    "    R, s_n, p_n = select_code_rate(ema_value, f_ec, R_range, n, d)\n",
    "    rows.append([f\"{E_mu_Z:.16f}\", R, s_n, p_n])  # 4 столбца: E, R, s_n, p_n\n",
    "\n",
    "# Сохраним результат\n",
    "pd.DataFrame(rows).to_csv(\"submission.csv\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidao_baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
